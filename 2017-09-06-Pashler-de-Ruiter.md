2017-09-06-Pashler-de-Ruiter
================
Rick O. Gilmore
2017-09-05 16:39:14

Purpose
-------

Discuss [Pashler & de Ruiter (2017)](https://www.psychologicalscience.org/observer/taking-responsibility-for-our-fields-reputation) paper.

Reading(s)
----------

-   Pashler, H., & de Ruiter, J. P. (2017). Taking Responsibility for Our Field’s Reputation. APS observer, 30(30/8). Retrieved September 4, 2017, from <https://www.psychologicalscience.org/observer/taking-responsibility-for-our-fields-reputation>

### Supplemental

-   Anderson, C. J., Bahník, Š., Barnett-Cowan, M., Bosco, F. A., Chandler, J., Chartier, C. R., Cheung, F., et al. (2016). Response to comment on “Estimating the reproducibility of psychological science.” Science, 351(6277), 1037. Retrieved from <http://dx.doi.org/10.1126/science.aad9163>
-   Bem, D. J. (2011). Feeling the future: experimental evidence for anomalous retroactive influences on cognition and affect. Journal of personality and social psychology, 100(3), 407–425. Retrieved from <http://dx.doi.org/10.1037/a0021524>
-   Bem, D., Tressoldi, P., Rabeyron, T., & Duggan, M. (2015). Feeling the future: A meta-analysis of 90 experiments on the anomalous anticipation of random future events. F1000Research, 4, 1188. Retrieved from <http://dx.doi.org/10.12688/f1000research.7177.2>
-   Button, K. S., Ioannidis, J. P. A., Mokrysz, C., Nosek, B. A., Flint, J., Robinson, E. S. J., & Munafò, M. R. (2013). Power failure: why small sample size undermines the reliability of neuroscience. Nature Reviews Neuroscience, 14(5), 365–376. Retrieved December 14, 2016, from <http://www.nature.com/nrn/journal/v14/n5/full/nrn3475.html>
-   Etz, A., & Vandekerckhove, J. (2016). A Bayesian Perspective on the Reproducibility Project: Psychology. PloS one, 11(2), e0149794. Retrieved October 9, 2016, from <http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0149794>
-   Gilbert, D. T., King, G., Pettigrew, S., & Wilson, T. D. (2016). Comment on “Estimating the reproducibility of psychological science.” Science, 351(6277), 1037–1037. Retrieved March 27, 2016, from <http://science.sciencemag.org/content/351/6277/1037.2-> Open Science Collaboration. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716–aac4716. American Association for the Advancement of Science. Retrieved February 17, 2017, from <http://science.sciencemag.org/content/349/6251/aac4716>
-   Gilmore, R. O., & Adolph, K. E. (2017). Video can make behavioural science more reproducible. Nature Human Behavior, 1. Retrieved from <http://dx.doi.org/10.1038/s41562-017-0128>
-   Mischel, W. (2011). Becoming a cumulative science. APS observer, 22(1). Retrieved from <https://www.psychologicalscience.org/observer/becoming-a-cumulative-science>
-   Morey, R. D., & Lakens, D. (2016). Why most of psychology is statistically unfalsifiable. Manuscript submitted for publication. Available at: github.com/richarddmorey/psychology\_resolution/blob/master/paper/response.pdf. [Shiny app simulations](https://richarddmorey.shinyapps.io/RPP_results/).
-   Munafò, M. R., Nosek, B. A., Bishop, D. V. M., Button, K. S., Chambers, C. D., Sert, N. P. du, Simonsohn, U., et al. (2017). A manifesto for reproducible science. Nature Human Behaviour, 1, 0021. Retrieved January 10, 2017, from <http://www.nature.com/articles/s41562-016-0021>
-   Pashler, H., & Harris, C. R. (2012). Is the Replicability Crisis Overblown? Three Arguments Examined. Perspectives on psychological science: a journal of the Association for Psychological Science, 7(6), 531–536. Retrieved October 22, 2016, from <http://pps.sagepub.com/content/7/6/531>
-   Szucs, D., & Ioannidis, J. P. A. (2017). Empirical assessment of published effect sizes and power in the recent cognitive neuroscience and psychology literature. PLoS biology, 15(3), e2000797. Retrieved from <http://dx.doi.org/10.1371/journal.pbio.2000797>
-   Wagenmakers, E.-J., Wetzels, R., Borsboom, D., & van der Maas, H. L. J. (2011). Why psychologists must change the way they analyze their data: the case of psi: comment on Bem (2011). Journal of personality and social psychology, 100(3), 426–432. Retrieved from <http://dx.doi.org/10.1037/a0022790>

Issues
------

-   Is there a "reproducibility crisis" in psychology (or other sciences)?
-   Has psychology's reputation suffered?
-   If so
    -   Why?
    -   What can and should be done?
-   If not...

Is there a "reproducibility crisis"?
====================================

------------------------------------------------------------------------

<a href="http://www.nature.com/polopoly_fs/7.36716.1469695923!/image/reproducibility-graphic-online1.jpeg_gen/derivatives/landscape_630/reproducibility-graphic-online1.jpeg" height=450px> <img src="http://www.nature.com/polopoly_fs/7.36716.1469695923!/image/reproducibility-graphic-online1.jpeg_gen/derivatives/landscape_630/reproducibility-graphic-online1.jpeg" height=500px> </a>

[Baker 2016](http://doi.org/10.1038/533452a)

Not just in psychology
----------------------

<div class="centered">
<a href="http://www.nature.com/polopoly_fs/7.36718.1464174471!/image/reproducibility-graphic-online3.jpg_gen/derivatives/landscape_630/reproducibility-graphic-online3.jpg"> <img src="http://www.nature.com/polopoly_fs/7.36718.1464174471!/image/reproducibility-graphic-online3.jpg_gen/derivatives/landscape_630/reproducibility-graphic-online3.jpg"" height=500px> </a>

Has psychology's reputation suffered?
=====================================

Comments on [Reproducibility Project: Psychology](https://osf.io/ezcuj/)
------------------------------------------------------------------------

Yong, E. (2016, March 4). Psychology’s Replication Crisis Can’t Be Wished Away. The Atlantic. Retrieved September 4, 2017, from <http://www.theatlantic.com/science/archive/2016/03/psychologys-replication-crisis-cant-be-wished-away/472272/>

Handwerk, B. (n.d.). Scientists Replicated 100 Psychology Studies, and Fewer Than Half Got the Same Results. Smithsonian. Retrieved September 4, 2017, from <http://www.smithsonianmag.com/science-nature/scientists-replicated-100-psychology-studies-and-fewer-half-got-same-results-180956426/>

------------------------------------------------------------------------

<a href="http://doi.org/10.1037/a0039405"> <img src="https://raw.githubusercontent.com/gilmore-lab/cog-bbag-talk-2017-02-22/master/img/ferguson-everybody-knows.jpg" width=900px> </a>

[Ferguson 2015](http://doi.org/10.1037/a0039405)

If so, why?
===========

------------------------------------------------------------------------

<a href="http://www.nature.com/polopoly_fs/7.36719.1464174488!/image/reproducibility-graphic-online4.jpg_gen/derivatives/landscape_630/reproducibility-graphic-online4.jpg"> <img src="http://www.nature.com/polopoly_fs/7.36719.1464174488!/image/reproducibility-graphic-online4.jpg_gen/derivatives/landscape_630/reproducibility-graphic-online4.jpg"> </a>

[Baker 2016](http://doi.org/10.1038/533452a)

Threats to credibility in *psychology*
--------------------------------------

-   Scandal: Stapel, Hauser
-   Implausible claims: [Bem 2011](http://dx.doi.org/10.1037/a0021524); [Bem et al. 2015](http://dx.doi.org/10.12688/f1000research.7177.2); [Wagenmakers et al. 2011](http://dx.doi.org/10.1037/a0022790)
-   Challenges to reproducibility: [Open Science Collaboration 2015](http://science.sciencemag.org/content/349/6251/aac4716); [Anderson et al. 2016](Anderson,%20C.%20J.,%20Bahník,%20Š.,%20Barnett-Cowan,%20M.,%20Bosco,%20F.%20A.,%20Chandler,%20J.,%20Chartier,%20C.%20R.,%20Cheung,%20F.,%20et%20al.%20(2016).%20Response%20to%20comment%20on%20“Estimating%20the%20reproducibility%20of%20psychological%20science.”%20Science,%20351(6277),%201037.%20Retrieved%20from%20http://dx.doi.org/10.1126/science.aad9163); [Gilbert et al 2016](http://science.sciencemag.org/content/349/6251/aac4716); [Etz & Vandekerckhove 2016](http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0149794); [Morey & Lakens 2016](github.com/richarddmorey/psychology_resolution/blob/master/paper/response.pdf).
-   Low power: [Button et al. 2013](http://www.nature.com/nrn/journal/v14/n5/full/nrn3475.html); [Poldrack et al. 2017](Poldrack,%20R.%20A.,%20Baker,%20C.%20I.,%20Durnez,%20J.,%20Gorgolewski,%20K.%20J.,%20Matthews,%20P.%20M.,%20Munafò,%20M.%20R.,%20Nichols,%20T.%20E.,%20et%20al.%20(2017).%20Scanning%20the%20horizon:%20towards%20transparent%20and%20reproducible%20neuroimaging%20research.%20Nature%20reviews.%20Neuroscience,%20advance%20online%20publication.%20Retrieved%20January%206,%202017,%20from%20http://www.nature.com/nrn/journal/vaop/ncurrent/full/nrn.2016.167.html); [Szucs & Ioannides 2017](http://dx.doi.org/10.1371/journal.pbio.2000797)
-   Statistical practices: flexible stopping rules, *p*-hacking, reporting errors, ...

If so, what to do?
==================

"Truth in packaging"
--------------------

> "...explicitly and conservatively label the degree of support enjoyed by any research finding that is mentioned."

> "Over and over again, we see literatures that are resplendent with varied and imaginative conceptual replications, and yet somehow no result in particular ever seems to replicate when a direct replication is undertaken. Clever new meta-analytic tools will not rescue us either. For instance, precognition research, claiming support for ideas that would violate the laws of physics, has been given a bill of good health by the “p-curve” technique (Simonsohn, Nelson, & Simmons, 2014; Bem, Tressoldi, Rabeyron, & Duggan, 2015)."

"Investigator accountability"
-----------------------------

> "Our field also needs to persuade individual scientists to respond more positively, as many have done, when other researchers fail to replicate their original results. Blaming a failed replication on unknown moderating factors should not be the acceptable response. If the original investigators know how to get the effect, let them step forward, repeat it, and show us all how to do it."

> "We propose a standard of accountability common in many professional fields. The code of conduct for professional engineers, for example, holds them accountable for the structures they design. And prior to 2010, the (rare) published failures to replicate seemed to breed a sense of obligation on the part of original investigators to try to recreate their phenomena. In the past few years, however, that sort of accountability seems to have diminished."

Related proposals
-----------------

-   [Munafò et al. 2017](http://www.nature.com/articles/s41562-016-0021)
-   Make data, materials, code sharing commonplace
    -   Plan to share early on
    -   Make seeking [permission to share data](https://osf.io/9d5hr/) standard practice
-   Adopt tools that make open science workflows easy ([RStudio](http://rstudio.com), [Jupyter](http://http://jupyter.org/) notebooks, GitHub)
-   Use video to record procedures ([Gilmore & Adolph 2017](http://dx.doi.org/10.1038/s41562-017-0128))

If not...
=========

Reasons not to worry
--------------------

-   Problems limited to certain sub-fields
-   Making mountains out of molehills
-   Peer review and competition will (eventually) sort things out
