---
title: "Change your alpha"
author: "Rick Gilmore and Brad Wyble"
date: "`r Sys.time()`"
output: 
  github_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

# From https://gist.github.com/smithdanielle/9913897
# check.packages function: install and load multiple R packages.
# Check to see if packages are installed. Install them if they are not, then load them into the R session.
check.packages <- function(pkg){
    new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
    if (length(new.pkg)) 
        install.packages(new.pkg, dependencies = TRUE)
    sapply(pkg, require, character.only = TRUE)
}

packages <- c("tidyverse", "pBrackets")
check.packages(packages)
```

## What researchers should do

- Make $\alpha=.005$ the new standard for Null Hypothesis Statistical Testing for *new discoveries*
- Label findings with $.005<p<.05$ as 'suggestive'
- Focus attention on accumulating evidence ([Cummings 2012 Fig 1.1](##cummings-2012-fig-1.1); [Cummings 2012 Fig 2](#cummings-2012-fig-1.2))

## Why should they do this

- Practical, actionable, understandable, will improve reproducibility
- Fits with current practices & training thus potential for broad adoption
- Doesn't require overhauling the machinery of inference
- $p<.005$ consistent with [stronger evidence in favor of $H_1$](#benjamin-fig-1) under various scenarios
- Would substantially [reduce false positive rates](#benjamin-fig-2)

## Cummings 2012 Fig 1.1

[Cummings 2012](https://thenewstatistics.com/itns/)

```{r cummings-fig-1.1}
n_lucky = 22
n_noluck = 17

m_diff_lucky = 3.61
m_diff_noluck = 2.23

sd_diff_lucky = 6.97
sd_diff_noluck = 7.59

CI_width = .95

# Calculate CI
error_lucky <- qnorm((1-CI_width)/2)*sd_diff_lucky/sqrt(n_lucky)
left_lucky <- m_diff_lucky - error_lucky
right_lucky <- m_diff_lucky + error_lucky
(CI_lucky <- c(left_lucky, right_lucky))

# Calculate CI
error_noluck <- qnorm((1-CI_width)/2)*sd_diff_noluck/sqrt(n_noluck)
left_noluck <- m_diff_noluck - error_noluck
right_noluck <- m_diff_noluck + error_noluck
(CI_noluck <- c(left_noluck, right_noluck))

# plot CI
df <- data.frame(m_diff = c(m_diff_lucky, m_diff_noluck),
                 left_ci = c(left_lucky, left_noluck),
                 right_ci = c(right_lucky, right_noluck),
                 study = c("Lucky (2008)", "Noluck (2008)"))

library(tidyverse)

df %>% ggplot() +
  aes(m_diff, study) +
  geom_point() +
  geom_errorbarh(aes(xmax = right_ci, xmin = left_ci), height=.2) +
  xlab("Difference between the means") +
  ggtitle("One study shows a significant effect; the other does not")
```

## Cummings 2012 Fig 1.2

[Cummings 2012](https://thenewstatistics.com/itns/)

```{r cummings-fig-1.2}
# Equations from Cummings pp. 211
var_lucky = (sd_diff_lucky^2)/n_lucky
w_lucky = 1/(var_lucky)

var_noluck = (sd_diff_noluck^2)/n_noluck
w_noluck = 1/(var_noluck)

(m_meta = (m_diff_lucky*w_lucky + m_diff_noluck*w_noluck)/(w_lucky + w_noluck))
var_m_meta = 1/((w_lucky + w_noluck))
error_m_meta = abs(qnorm((1-CI_width)/2)*sqrt(var_m_meta))
m_meta_left = m_meta - error_m_meta
m_meta_right = m_meta + error_m_meta
(m_meta_ci = c(m_meta_left, m_meta_right))

df_meta = data.frame(m_meta = m_meta, type = "meta", right_ci = m_meta_right, left_ci = m_meta_left)

df_meta %>% ggplot() +
  aes(m_meta, type) +
  geom_point() +
  geom_errorbarh(aes(xmax = right_ci, xmin = left_ci), height=.2) +
  ggtitle("Results of meta-analysis on Lucky (2008) and Noluck (2008)") +
  xlim(-1,7) +
  xlab("Difference between the means")
```

## Benjamin Fig 1

```{r  benjamin-et-al-2017-figure-1, echo=FALSE}
# The following code was copied from the Benjamin et al. 2017 [supplemental material](https://static-content.springer.com/esm/art%3A10.1038%2Fs41562-017-0189-z/MediaObjects/41562_2017_189_MOESM1_ESM.pdf) and reformatted slightly for better code readability.

type1 = .005
type1Power = 0.05
type2 = 0.25
p = 1 - c(9000:9990) / 10000
xbar = qnorm(1 - p / 2)

# alternative based on 80% POWER IN 5% TEST
muPower = qnorm(1 - type2) + qnorm(1 - type1Power / 2)
bfPow = 0.5 * (dnorm(xbar, muPower, 1) + dnorm(xbar, -muPower, 1)) / dnorm(xbar, 0, 1)
muUMPBT = qnorm(0.9975)
bfUMPBT = 0.5 * (dnorm(xbar, muUMPBT, 1) + dnorm(xbar, -muUMPBT, 1)) / dnorm(xbar, 0, 1)

# two-sided "LR" bound
bfLR = 0.5 / exp(-0.5 * xbar ^ 2)
bfLocal = -1 / (2.71 * p * log(p))

#coordinates for dashed lines
data = data.frame(p, bfLocal, bfLR, bfPow, bfUMPBT)
U_005 = max(data$bfLR[data$p == "0.005"])
L_005 = min(data$bfLocal[data$p == "0.005"])
U_05 = max(data$bfLR[data$p == "0.05"])
L_05 = min(data$bfUMPBT[data$p == "0.05"])
# Local bound; no need for two-sided adjustment

#plot margins
par(mai = c(0.8, 0.8, .1, 0.4))
par(mgp = c(2, 1, 0))

plot.new()

matplot(
  p,
  cbind(bfLR, -1 / (2.71 * p * log(p))),
  type = 'n',
  log = 'xy',
  xlab = expression(paste(italic(P), "-value")),
  ylab = "Bayes Factor",
  ylim = c(0.3, 100),
  bty = "n",
  xaxt = "n",
  yaxt = "n"
)

lines(p, bfPow, col = "red", lwd = 2.5)
lines(p, bfLR, col = "black", lwd = 2.5)
lines(p, bfUMPBT, col = "blue", lwd = 2.5)
lines(p, bfLocal, col = "green", lwd = 2.5)

legend(
  0.015,
  100,
  c(
    expression(paste("Power")),
    "Likelihood Ratio Bound",
    "UMPBT",
    expression(paste("Local-", italic(H)[1], " Bound"))
  ),
  lty = c(1, 1, 1, 1),
  lwd = c(2.5, 2.5, 2.5, 2.5),
  col = c("red", "black", "blue", "green"),
  cex = 0.8
)

#text(0.062,65, "\u03B1", font =3, cex = 0.9)

#customizing axes 
#x axis
axis(
  side = 1,
  at = c(-2, 0.001, 0.0025, 0.005, 0.010, 0.025, 0.050, 0.100, 0.14),
  labels = c(
    "",
    "0.0010",
    "0.0025",
    "0.0050",
    "0.0100",
    "0.0250",
    "0.0500",
    "0.1000",
    ""
  ),
  lwd = 1,
  tck = -0.01,
  padj = -1.1,
  cex.axis = .8
)

#y axis on the left - main
axis(
  side = 2,
  at = c(-0.2, 0.3, 0.5, 1, 2, 5, 10, 20, 50, 100),
  labels = c(
    "",
    "0.3",
    "0.5",
    "1.0",
    "2.0",
    "5.0",
    "10.0",
    "20.0",
    "50.0",
    "100.0"
  ),
  lwd = 1,
  las = 1,
  tck = -0.01,
  hadj = 0.6,
  cex.axis = .8
)

#y axis on the left - secondary (red labels)
axis(
  side = 2,
  at = c(L_005, U_005),
  labels = c(13.9, 25.7),
  lwd = 1,
  las = 1,
  tck = -0.01,
  hadj = 0.6,
  cex.axis = .6,
  col.axis = "red"
  )

#y axis on the right - main
axis(
  side = 4,
  at = c(-0.2, 0.3, 0.5, 1, 2, 5, 10, 20, 50, 100),
  labels = c(
  "",
  "0.3",
  "0.5",
  "1.0",
  "2.0",
  "5.0",
  "10.0",
  "20.0",
  "50.0",
  "100.0"
  ),
  lwd = 1,
  las = 1,
  tck = -0.01,
  hadj = 0.4,
  cex.axis = .8
  )
  
#y axis on the right - secondary (red labels) 
axis(
  side = 4,
  at = c(L_05, U_05),
  labels = c(2.4, 3.4),
  lwd = 1,
  las = 1,
  tck = -0.01,
  hadj = 0.4,
  cex.axis = .6,
  col.axis = "red"
  )
  
###dashed lines
segments(x0 = 0.000011, y0= U_005, x1 = 0.005, y1 = U_005, col = "gray40", lty = 2)
segments(x0 = 0.000011, y0= L_005, x1 = 0.005, y1 = L_005, col = "gray40", lty = 2)
segments(x0 = 0.005, y0= 0.00000001, x1 = 0.005, y1 = U_005, col = "gray40", lty = 2)
segments(x0 = 0.05, y0= U_05, x1 = 0.14, y1 = U_05, col = "gray40", lty = 2)
segments(x0 = 0.05, y0= L_05, x1 = 0.14, y1 = L_05, col = "gray40", lty = 2)
segments(x0 = 0.05, y0= 0.00000001, x1 = 0.05, y1 = U_05, col = "gray40", lty = 2)
```

## Benjamin Fig 2

```{r benjamin-et-al-2017-figure-2, echo=FALSE}
pow1=c(5:999)/1000 # power range for 0.005 tests 
pow2=c(50:999)/1000 # power range for 0.05 tests 
alpha=0.005 # test size
pi0=5/6 # prior probability
N=10^6 # doesn't matter

#graph margins 
par(mai=c(0.8,0.8,0.1,0.1)) 
par(mgp=c(2,1,0))
plot(pow1,alpha*N*pi0/(alpha*N*pi0+pow1*(1-pi0)*N),type='n',ylim = c(0,1), xlim = c(0,1.5),
xlab='Power ',
ylab='False positive rate', bty="n", xaxt="n", yaxt="n") 

#grid lines

segments(x0 = -0.058, y0 = 0, x1 = 1, y1 = 0, lty=1, col = "gray92") 
segments(x0 = -0.058, y0 = 0.2, x1 = 1, y1 = 0.2, lty=1, col = "gray92")
segments(x0 = -0.058, y0 = 0.4, x1 = 1, y1 = 0.4, lty=1, col = "gray92")
segments(x0 = -0.058, y0 = 0.6, x1 = 1, y1 = 0.6, lty=1, col = "gray92")
segments(x0 = -0.058, y0 = 0.8, x1 = 1, y1 = 0.8, lty=1, col = "gray92")
segments(x0 = -0.058, y0 = 1, x1 = 1, y1 = 1, lty=1, col = "gray92")

lines(
  pow1,
  alpha * N * pi0 / (alpha * N * pi0 + pow1 * (1 - pi0) * N),
  lty = 1,
  col = "blue",
  lwd = 2
  )

odd_1_5_1 = alpha * N * pi0 / (alpha * N * pi0 + pow1[995] * (1 - pi0) * N)
  
alpha=0.05
pi0=5/6


lines(
  pow2,
  alpha*N*pi0/(alpha*N*pi0+pow2*(1- pi0)*N),
  lty=2,
  col="blue",
  lwd=2
  )
odd_1_5_2 = alpha*N*pi0/(alpha*N*pi0+pow2[950]*(1-pi0)*N)

alpha=0.05
pi0=10/11
lines(
  pow2,
  alpha * N * pi0 / (alpha * N * pi0 + pow2 * (1 - pi0) * N),
  lty = 2,
  col = "red",
  lwd = 2
  )

odd_1_10_2 = alpha*N*pi0/(alpha*N*pi0+pow2[950]*(1-pi0)*N) 
alpha=0.005
pi0=10/11

lines(
  pow1,
  alpha * N * pi0 / (alpha * N * pi0 + pow1 * (1 - pi0) * N),
  lty = 1,
  col = "red",
  lwd = 2
  )

odd_1_10_1 = alpha * N * pi0 / (alpha * N * pi0 + pow1[995] * (1 - pi0) * N)
  
alpha=0.05 
pi0=40/41

lines(
  pow2,
  alpha * N * pi0 / (alpha * N * pi0 + pow2 * (1 - pi0) * N),
  lty = 2,
  col = "green",
  lwd = 2
  )

odd_1_40_2 = alpha * N * pi0 / (alpha * N * pi0 + pow2[950] * (1 - pi0) *
  N
)
  
alpha=0.005
pi0=40/41

lines(
  pow1,
  alpha * N * pi0 / (alpha * N * pi0 + pow1 * (1 - pi0) * N),
  lty = 1,
  col = "green",
  lwd = 2
  )
  
odd_1_40_1 = alpha * N * pi0 / (alpha * N * pi0 + pow1[995] * (1 - pi0) *N)
  
#customizing axes 
axis(
  side = 2,
  at = c(-0.5, 0, 0.2, 0.4, 0.6, 0.8, 1.0),
  labels = c("", "0.0", "0.2", "0.4", "0.6", "0.8", "1.0"),
  lwd = 1,
  las = 1,
  tck = -0.01,
  hadj = 0.4,
  cex.axis = .8
  )
  
axis(
  side = 1,
  at = c(-0.5, 0, 0.2, 0.4, 0.6, 0.8, 1.0),
  labels = c("", "0.0", "0.2", "0.4", "0.6", "0.8", "1.0"),
  lwd = 1,
  las = 1,
  tck = -0.01,
  padj = -1.1,
  cex.axis = .8
  )
  
legend(
  1.05,
  1,
  c("Prior odds = 1:40", "Prior odds = 1:10", "Prior odds = 1:5"),
  pch = c(15, 15, 15),
  col = c("green", "red", "blue"),
  cex = 1
)
  
############### Use these commands 
if(!('pBrackets' %in% installed.packages()[,1])) {
  install.packages('pBrackets')
  require(pBrackets)}

#add text and brackets

text(1.11,
     (odd_1_5_2 + odd_1_40_2) / 2,
     expression(paste(italic(P), "< 0.05 threshold")),
     cex = 0.9,
     adj = 0
)

text(1.11,
     (odd_1_5_1 + odd_1_40_1) / 2,
     expression(paste(italic(P), "< 0.005 threshold")),
     cex = 0.9,
     adj = 0
)
     
brackets(
     1.03,
     odd_1_40_1,
     1.03,
     odd_1_5_1,
     h = NULL,
     ticks = 0.5,
     curvature = 0.7,
     type = 1,
     col = 1,
     lwd = 1,
     lty = 1,
     xpd = FALSE
     )
     
brackets(
  1.03,
  odd_1_40_2,
  1.03,
  odd_1_5_2,
  h = NULL,
  ticks = 0.5,
  curvature = 0.7,
  type = 1,
  col = 1,
  lwd = 1,
  lty = 1,
  xpd = FALSE
  )
```

## Sources

Benjamin, D. J., Berger, J., Johannesson, M., Nosek, B. A., Wagenmakers, E.-J., Berk, R., Bollen, K., et al. (2017). Redefine statistical significance. *Nature Human Behavior*, full text available from <http://rdcu.be/v4Sr>. [Supplemental material](https://static-content.springer.com/esm/art%3A10.1038%2Fs41562-017-0189-z/MediaObjects/41562_2017_189_MOESM1_ESM.pdf).

Cumming, G. (2013). Understanding The New Statistics: Effect Sizes, Confidence Intervals, and Meta-Analysis. Routledge. Retrieved from https://market.android.com/details?id=book-1W6laNc7Xt8C